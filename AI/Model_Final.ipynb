{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note book for the model architecture and training part"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring TensorFlow: GPU Growth and Soft Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loadind and balance the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../frameRecorder/databis.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.sum()\n",
    "print(counts)\n",
    "\n",
    "df = df.drop(df[df.z == 1].sample(frac=0.6).index)\n",
    "df = df.drop(df[df.d == 1].sample(frac=0.04).index)\n",
    "df = df.drop(df[df.zq == 1].sample(frac=0.4).index)\n",
    "df = df.drop(df[df.zd == 1].sample(frac=0.4).index)\n",
    "\n",
    "new_counts = df.sum()\n",
    "print(new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:, 0], df.iloc[:, 1:]\n",
    "print(X[0:10])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Exemple of the preprocessing we perform on a road image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('../frameRecorder/screenshots/1682028946060.png')\n",
    "# make it one channel\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "img = cv.Canny(img, threshold1=120, threshold2=220)\n",
    "img = img[100: , :]\n",
    "\n",
    "lanes = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "lanes[:, :, 0] = img\n",
    "lanes[:, :, 1] = img\n",
    "lanes[:, :, 2] = img\n",
    "\n",
    "\n",
    "# get the lines from lanes image \n",
    "lines = cv.HoughLinesP(img, rho=1, theta=np.pi/90, threshold=70, minLineLength=20, maxLineGap=50)\n",
    "\n",
    "# draw the lines on the lanes image\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv.line(lanes, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "lanes = cv.resize(lanes, (200, 66))\n",
    "\n",
    "# show the image\n",
    "plt.imshow(lanes)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Extraction: Road and Map Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_road = []\n",
    "XX_map = []\n",
    "progress = 0\n",
    "total = len(X)\n",
    "for i in X:\n",
    "    img = cv.imread('../frameRecorder/screenShots/' + str(i) + '.png')\n",
    "\n",
    "    # part to get the data about the road\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = cv.Canny(img, threshold1=120, threshold2=220)\n",
    "    img = img[100: , :]\n",
    "\n",
    "    lanes = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    lanes[:, :, 0] = img\n",
    "    lanes[:, :, 1] = img\n",
    "    lanes[:, :, 2] = img\n",
    "\n",
    "\n",
    "    # get the lines from lanes image \n",
    "    lines = cv.HoughLinesP(img, rho=1, theta=np.pi/90, threshold=70, minLineLength=20, maxLineGap=50)\n",
    "\n",
    "    # draw the lines on the lanes image\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv.line(lanes, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "    lanes = cv.resize(lanes, (200, 66))\n",
    "    \n",
    "    lanes = lanes / 255\n",
    "    XX_road.append(lanes)\n",
    "    # end of part to get the data about the road\n",
    "    \n",
    "    # part to get the data about the map\n",
    "    img = cv.imread('../frameRecorder/screenShots/' + str(i) + '_map.png')\n",
    "    img = img / 255\n",
    "    XX_map.append(img)\n",
    "    # end of part to get the data about the map\n",
    "\n",
    "    progress += 1\n",
    "    print(str(progress) + '/' + str(total))\n",
    "    os.system('cls')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spliting the data into Train, Test and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training , validation and testing sets\n",
    "X_train_road, X_test_road, X_train_map, X_test_map, y_train, y_test = train_test_split(XX_road, XX_map, y, test_size=0.2, random_state=42)\n",
    "X_test_road, X_val_road, X_test_map, X_val_map, y_test, y_val = train_test_split(X_test_road, X_test_map, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_road = np.array(X_train_road)\n",
    "X_test_road = np.array(X_test_road)\n",
    "X_val_road = np.array(X_val_road)\n",
    "X_train_map = np.array(X_train_map)\n",
    "X_test_map = np.array(X_test_map)\n",
    "X_val_map = np.array(X_val_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_road.shape)\n",
    "print(X_test_road.shape)\n",
    "print(X_val_road.shape)\n",
    "print(X_train_map.shape)\n",
    "print(X_test_map.shape)\n",
    "print(X_val_map.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Creating the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    model_1 = Sequential([\n",
    "        Conv2D(24, (5, 5), (2, 2), activation='relu', input_shape=(66, 200, 3)),\n",
    "        Conv2D(36, (5, 5), (2, 2), activation='relu'),\n",
    "        Conv2D(48, (5, 5), (2, 2), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "    ])\n",
    "    # another model \n",
    "    model_2 = Sequential([\n",
    "        Conv2D(22, kernel_size=(3, 3), activation='relu', input_shape=(100, 145, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(28, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(34, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(40, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(15, activation='relu'),\n",
    "    ])\n",
    "\n",
    "    # concatenate two models\n",
    "    combinedInput = layers.concatenate([model_1.output, model_2.output])\n",
    "    x = Dense(8, activation=\"softmax\")(combinedInput)\n",
    "    model = keras.Model(inputs=[model_1.input, model_2.input], outputs=x)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Saving a graph representation of the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a graph of the model\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    tf.keras.utils.plot_model(model, \"model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image model.png \n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Training the model and saving the best model found at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # select the best model\n",
    "    checkpoint = ModelCheckpoint('final_model_v1_9_0.h5', monitor='val_accuracy', verbose=0, save_best_only=True, mode='auto')\n",
    "    # train the model\n",
    "    history = model.fit([X_train_road, X_train_map], y_train, epochs=25, batch_size=32, validation_data=([X_val_road, X_val_map], y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Testing the model and plotting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "with tf.compat.v1.Session(config=config) as sess:\n",
    "    # load the model\n",
    "    model = load_model('final_model_v1_9_0.h5') \n",
    "\n",
    "    loss, acc = model.evaluate([X_test_road, X_test_map], y_test, verbose=2)\n",
    "    print('Test Accuracy: {}'.format(acc))\n",
    "    print('Test Loss: {}'.format(loss))\n",
    "\n",
    "    # plot the accuracy\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # plot the loss\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
